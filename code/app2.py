import streamlit as st
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import networkx as nx
from pyvis.network import Network
import plotly.graph_objects as go
import xgboost as xgb
from sklearn.preprocessing import MinMaxScaler
import pickle
import os
import tempfile
import warnings
import sys

# === å¼•å…¥ç½‘ç»œåº“ ===
from openai import OpenAI
import httpx

# ================= 1. åŸºç¡€é…ç½® =================
warnings.filterwarnings("ignore")

# è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
BASE_DIR = os.path.dirname(os.path.abspath(__file__))


def get_path(filename):
    return os.path.join(BASE_DIR, filename)


# ================= é¡µé¢é…ç½® =================
st.set_page_config(
    page_title="CaD-HSL æŠ€æœ¯è¶‹åŠ¿å¹³å°",
    page_icon="ğŸ”®",
    layout="wide"
)

# ================= LLM è¿æ¥é…ç½® (é’ˆå¯¹å†…ç½‘+VPNä¿®å¤) =================
# 1. æ‚¨çš„å†…ç½‘åœ°å€
LLM_BASE_URL = "https://b3237.gpu.act.buaa.edu.cn/v1"
# 2. Key (å†…ç½‘é€šå¸¸ä¸ºç©º)
LLM_API_KEY = "EMPTY"
# 3. æ¨¡å‹åç§° (æ³¨æ„ï¼šå¿…é¡»åŒ…å« ./ å‰ç¼€ï¼Œä¸æœåŠ¡å™¨è¿”å›ä¸€è‡´)
LLM_MODEL_NAME = "./DeepSeek-R1-0528-Qwen3-8B"


@st.cache_resource
def get_llm_client():
    """åˆå§‹åŒ–è¿æ¥ï¼Œå¼ºåˆ¶ç»•è¿‡ EasyConnect ä»£ç†"""
    try:
        # --- æ ¸å¿ƒä¿®å¤ï¼šå¼ºåˆ¶ httpx ä¸è¯»å–ç³»ç»Ÿä»£ç† ---
        mounts = {
            "http://": httpx.HTTPTransport(proxy=None),
            "https://": httpx.HTTPTransport(proxy=None),
        }

        # é…ç½® Client
        http_client = httpx.Client(
            verify=False,  # å¿½ç•¥å†…ç½‘è‡ªç­¾åè¯ä¹¦
            timeout=30.0,  # å¢åŠ è¶…æ—¶æ—¶é—´
            mounts=mounts,  # æŒ‚è½½æ— ä»£ç†ä¼ è¾“
            trust_env=False  # å½»åº•å¿½ç•¥ç¯å¢ƒå˜é‡ä¸­çš„ HTTP_PROXY
        )

        client = OpenAI(
            api_key=LLM_API_KEY,
            base_url=LLM_BASE_URL,
            http_client=http_client
        )

        # æ¡æ‰‹æµ‹è¯•ï¼šå°è¯•è·å–æ¨¡å‹åˆ—è¡¨
        client.models.list()

        return client, "âœ… å·²è¿æ¥: DeepSeek R1 (æ ¡å†…èŠ‚ç‚¹)"

    except Exception as e:
        # å¦‚æœå‡ºé”™ï¼Œè¿”å› None å’Œé”™è¯¯ä¿¡æ¯
        return None, f"âŒ è¿æ¥å¤±è´¥: {str(e)}"


# åˆå§‹åŒ–è¿æ¥
client, connection_status = get_llm_client()


def generate_ai_report(tech_name, drivers, growth_pct):
    """è°ƒç”¨ DeepSeek ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    if not client:
        return f"æ— æ³•ç”ŸæˆæŠ¥å‘Šã€‚åŸå› ï¼š{connection_status}"

    drivers_str = "ã€".join(drivers) if drivers else "å†å²æƒ¯æ€§åŠè‡ªèº«æŠ€æœ¯è¿­ä»£"

    prompt = f"""
    ä½ æ˜¯ä¸€ä½èµ„æ·±çš„äº§ä¸šç§‘æŠ€åˆ†æå¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹é‡åŒ–æ¨¡å‹çš„æ•°æ®ï¼Œä¸ºæ”¿åºœå†³ç­–è€…è§£è¯»æŠ€æœ¯è¶‹åŠ¿ã€‚

    ã€åˆ†æå¯¹è±¡ã€‘ï¼š{tech_name}
    ã€é¢„æµ‹è¶‹åŠ¿ã€‘ï¼šæœªæ¥ä¸€å¹´çƒ­åº¦é¢„æœŸå¢é•¿ {growth_pct:.1f}%
    ã€æ ¸å¿ƒé©±åŠ¨å› å­ã€‘ï¼š{drivers_str}

    è¯·ç”¨ä¸“ä¸šã€ç®€ç»ƒçš„è¯­è¨€ï¼ˆ200å­—ä»¥å†…ï¼‰å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
    1. **å½’å› åˆ†æ**ï¼šè§£é‡Šä¸ºä»€ä¹ˆè¿™äº›é©±åŠ¨å› å­ï¼ˆ{drivers_str}ï¼‰ä¼šä¿ƒè¿› {tech_name} çš„å‘å±•ï¼Ÿï¼ˆä¾‹å¦‚ï¼šäº§ä¸šé“¾ä¾›éœ€ã€åŸºå»ºèµ‹èƒ½ã€æˆ–å®è§‚é¡¹ç›®å…±æŒ¯ï¼‰
    2. **å•†ä¸šæ´å¯Ÿ**ï¼šè¿™åæ˜ äº†ä»€ä¹ˆå›½å®¶æˆ˜ç•¥æˆ–è¡Œä¸šè½¬å‹è¶‹åŠ¿ï¼Ÿ

    æ³¨æ„ï¼šè¾“å‡ºé€»è¾‘ä¸¥å¯†ï¼Œç›´æ¥ç»™å‡ºç»“è®ºï¼Œä¸è¦å †ç Œå¥—è¯ã€‚
    """

    try:
        response = client.chat.completions.create(
            model=LLM_MODEL_NAME,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç§‘æŠ€äº§ä¸šåˆ†æåŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.6,
            max_tokens=800
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ ç”Ÿæˆä¸­æ–­: {str(e)}"


# ================= æ¨¡å‹ç»“æ„å®šä¹‰ (å¿…é¡»ä¿ç•™ä»¥åŠ è½½ pth) =================
class HypergraphConv(nn.Module):
    def __init__(self, in_dim, out_dim):
        super().__init__()
        self.linear = nn.Linear(in_dim, out_dim)
        self.norm = nn.LayerNorm(out_dim)

    def forward(self, x, H, edge_weights):
        x = self.linear(x)
        edge_deg = H.sum(dim=1, keepdim=True).clamp(min=1.0)
        edge_feat = torch.matmul(H.transpose(1, 2), x) / edge_deg.transpose(1, 2)
        edge_feat = edge_feat * edge_weights.unsqueeze(-1)
        node_deg = H.sum(dim=2, keepdim=True).clamp(min=1.0)
        x_new = torch.matmul(H, edge_feat) / node_deg
        return self.norm(F.elu(x_new))


class CausalStructureLearner(nn.Module):
    def __init__(self, num_nodes, prior_matrix):
        super().__init__()
        prior_logits = torch.ones_like(prior_matrix) * -5.0
        mask = prior_matrix > 1e-4
        prior_logits[mask] = 1.0
        self.register_buffer('prior_logits', prior_logits)
        self.adj_delta = nn.Parameter(torch.zeros(num_nodes, num_nodes))

    def forward(self):
        adj = torch.sigmoid(self.prior_logits + self.adj_delta)
        return adj * (adj > 0.2).float()


class CaD_HSL_Model(nn.Module):
    def __init__(self, config, prior_matrix):
        super().__init__()
        self.node_emb = nn.Embedding(config['num_nodes'], config['embed_dim'])
        self.hg_conv1 = HypergraphConv(config['embed_dim'], config['hidden_dim'])
        self.hg_conv2 = HypergraphConv(config['hidden_dim'], config['hidden_dim'])
        self.causal_learner = CausalStructureLearner(config['num_nodes'], prior_matrix)
        self.gcn_lin = nn.Linear(config['embed_dim'], config['hidden_dim'])
        encoder_layer = nn.TransformerEncoderLayer(d_model=config['hidden_dim'] * 2, nhead=4, dim_feedforward=64,
                                                   batch_first=True)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=1)
        self.head_cls = nn.Linear(config['hidden_dim'] * 2, 1)
        self.head_reg = nn.Linear(config['hidden_dim'] * 2, 1)

    def forward(self, x, H, W): return None, None, self.causal_learner()


# ================= æ•°æ®åŠ è½½ =================
@st.cache_resource
def load_all_data():
    try:
        # 1. åŠ è½½å­—å…¸
        with open(get_path('dictionaries.pkl'), 'rb') as f:
            dicts = pickle.load(f)
        id2tech = dicts['id2tech']
        num_nodes = len(id2tech)

        # 2. åŠ è½½åºåˆ—æ•°æ®
        seq = torch.load(get_path('hypergraph_seq.pt'), map_location='cpu', weights_only=False)
        ts_matrix = np.zeros((len(seq), num_nodes))
        for t, item in enumerate(seq):
            if item['H'].numel() > 0:
                edge_vals = item['weights'][item['H'][1]]
                df_tmp = pd.DataFrame({'n': item['H'][0].numpy(), 'w': edge_vals.numpy()})
                for n, val in df_tmp.groupby('n')['w'].sum().items():
                    if n < num_nodes: ts_matrix[t, int(n)] = val

        scaler = MinMaxScaler()
        ts_norm = scaler.fit_transform(ts_matrix)
        df_norm = pd.DataFrame(ts_norm, columns=[id2tech[i] for i in range(num_nodes)])
        df_real = pd.DataFrame(ts_matrix, columns=[id2tech[i] for i in range(num_nodes)])

        # å¤„ç†æ—¶é—´ç´¢å¼•
        try:
            dates = pd.date_range(end='2024-12-31', periods=len(df_norm), freq='QE')
        except:
            dates = pd.date_range(end='2024-12-31', periods=len(df_norm), freq='Q')

        df_norm.index = dates
        df_real.index = dates

        # 3. åŠ è½½æ¨¡å‹
        device = 'cpu'
        prior = torch.load(get_path('granger_prior.pt'), map_location=device, weights_only=False)
        config = {'num_nodes': num_nodes, 'embed_dim': 32, 'hidden_dim': 32}
        model = CaD_HSL_Model(config, prior).to(device)

        model_path = get_path('cad_hsl_model.pth')
        try:
            model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))
        except:
            model.load_state_dict(torch.load(model_path, map_location=device, weights_only=False))

        model.eval()
        adj_matrix = model.causal_learner().detach().cpu().numpy()

        # 4. åŠ è½½æŒ‡æ ‡
        metrics_df = pd.read_csv(get_path('all_tech_metrics.csv'))

        return df_norm, df_real, adj_matrix, id2tech, scaler, metrics_df

    except Exception as e:
        st.error(f"âŒ æ•°æ®åŠ è½½é”™è¯¯: {str(e)}")
        st.stop()


# æ‰§è¡ŒåŠ è½½
with st.spinner("æ­£åœ¨åˆå§‹åŒ–æ•°æ®å¼•æ“..."):
    df_norm, df_real, adj_matrix, id2tech, scaler, metrics_df = load_all_data()


# ================= è¾…åŠ©å‡½æ•°ï¼šå›¾æ„å»º =================
def build_networkx_graph(adj, id2tech, threshold=0.7):
    G = nx.DiGraph()
    rows, cols = np.where(adj > threshold)
    for r, c in zip(rows, cols):
        if r == c: continue
        weight = float(adj[r, c])
        src = id2tech[r]
        dst = id2tech[c]
        G.add_edge(src, dst, weight=weight, title=f"{weight:.2f}")
    return G


def plot_pyvis(G, height="600px", select_node=None, mode="full"):
    if len(G.nodes) == 0: return "<div>å›¾ä¸ºç©º</div>"
    net = Network(height=height, width="100%", bgcolor="#ffffff", font_color="black", directed=True)
    net.from_nx(G)
    for node in net.nodes:
        if select_node and node['id'] == select_node:
            node['color'] = '#FF5733'  # é€‰ä¸­é«˜äº®
            node['size'] = 30
        else:
            node['color'] = '#4B8BBE'
            node['size'] = 15

    # ç‰©ç†é…ç½®
    if mode == "full":
        net.set_options("""
        var options = {
          "physics": { "forceAtlas2Based": { "gravitationalConstant": -50, "springLength": 100, "damping": 0.4 } }
        }
        """)
    else:
        net.set_options("""
        var options = {
          "physics": { "barnesHut": { "gravitationalConstant": -3000, "springLength": 95, "avoidOverlap": 1 } }
        }
        """)

    try:
        fd, path = tempfile.mkstemp(suffix=".html")
        os.close(fd)
        net.save_graph(path)
        with open(path, 'r', encoding='utf-8') as f:
            html = f.read()
        os.remove(path)
        return html
    except:
        return "<div>ç»˜å›¾é”™è¯¯</div>"


# ================= ç•Œé¢ä¸»é€»è¾‘ =================
st.sidebar.title("ğŸ”® CaD-HSL é©¾é©¶èˆ±")
page = st.sidebar.radio("é€‰æ‹©åŠŸèƒ½æ¨¡å—", ["å…¨æ™¯æŠ€æœ¯å…³è”å›¾", "ç‰¹å®šæŠ€æœ¯äºŒé˜¶å›¾", "è¶‹åŠ¿é¢„æµ‹ä¸å¯¹æ¯”", "æ¨¡å‹æ€»æŒ‡æ ‡"])

st.sidebar.markdown("---")
if "âœ…" in connection_status:
    st.sidebar.success(connection_status)
else:
    st.sidebar.error(connection_status + "\n(å»ºè®®æ£€æŸ¥VPNçŠ¶æ€)")

# --- 1. å…¨æ™¯å›¾ ---
if page == "å…¨æ™¯æŠ€æœ¯å…³è”å›¾":
    st.title("ğŸŒ å…¨æ™¯æŠ€æœ¯å› æœå…³è”å›¾")
    col1, col2 = st.columns([3, 1])
    with col2:
        threshold = st.slider("å› æœå¼ºåº¦é˜ˆå€¼", 0.5, 0.95, 0.75, 0.05)

    G_full = build_networkx_graph(adj_matrix, id2tech, threshold)
    with col1:
        st.markdown(f"**èŠ‚ç‚¹æ•°:** {len(G_full.nodes)} | **å› æœè¿çº¿:** {len(G_full.edges)}")
        if len(G_full.nodes) > 0:
            html = plot_pyvis(G_full, height="600px", mode="full")
            st.components.v1.html(html, height=610)
        else:
            st.warning("å½“å‰é˜ˆå€¼ä¸‹æ— å…³è”æ•°æ®ã€‚")

# --- 2. äºŒé˜¶å›¾ ---
elif page == "ç‰¹å®šæŠ€æœ¯äºŒé˜¶å›¾":
    st.title("ğŸ•¸ï¸ ç‰¹å®šæŠ€æœ¯äºŒé˜¶å…³è”å›¾")
    col1, col2 = st.columns([1, 3])
    with col1:
        tech = st.selectbox("é€‰æ‹©æ ¸å¿ƒæŠ€æœ¯", list(id2tech.values()))
        thresh = st.slider("è¿æ¥å¼ºåº¦", 0.5, 0.95, 0.7)
    with col2:
        G_full = build_networkx_graph(adj_matrix, id2tech, thresh)
        if tech in G_full.nodes:
            G_ego = nx.ego_graph(G_full, tech, radius=1)
            G_viz = nx.DiGraph(G_ego)
            html = plot_pyvis(G_viz, height="600px", select_node=tech, mode="ego")
            st.components.v1.html(html, height=610)
        else:
            st.info(f"æŠ€æœ¯ **{tech}** åœ¨å½“å‰é˜ˆå€¼ä¸‹æ— å…³è”ã€‚")

# --- 3. è¶‹åŠ¿é¢„æµ‹ (å« LLM) ---
elif page == "è¶‹åŠ¿é¢„æµ‹ä¸å¯¹æ¯”":
    st.title("ğŸ“ˆ è¶‹åŠ¿é¢„æµ‹ä¸å½’å›  (Graph-RAG)")
    target = st.selectbox("æŠ€æœ¯é€‰æ‹©", list(id2tech.values()))

    # è·å–æŒ‡æ ‡å’Œé©±åŠ¨å› å­
    row = metrics_df[metrics_df['Tech'] == target]
    drivers = str(row['Drivers'].values[0]).split(',') if len(row) > 0 and pd.notna(row['Drivers'].values[0]) else []

    # Session State åˆå§‹åŒ–
    if 'report_content' not in st.session_state:
        st.session_state.report_content = None
    if 'last_target' not in st.session_state or st.session_state.last_target != target:
        st.session_state.report_content = None
        st.session_state.last_target = target

    if st.button("å¼€å§‹é¢„æµ‹ (2024-2025)", use_container_width=True):
        # 1. æ„é€ ç‰¹å¾
        df_feat = pd.DataFrame(index=df_norm.index)
        df_feat['Y'] = df_norm[target]
        for l in [1, 2, 3]: df_feat[f'S_L{l}'] = df_norm[target].shift(l)
        for d in drivers:
            if d in df_norm.columns:
                df_feat[f'D_{d}_L1'] = df_norm[d].shift(1)
        df_feat.dropna(inplace=True)

        # 2. è®­ç»ƒé¢„æµ‹
        train, test = df_feat.iloc[:-4], df_feat.iloc[-4:]
        m_base = xgb.XGBRegressor().fit(train[[c for c in df_feat.columns if 'S_L' in c]], train['Y'])
        m_causal = xgb.XGBRegressor().fit(train.drop('Y', axis=1), train['Y'])

        # 3. å­˜å…¥ Session
        st.session_state.p_base = m_base.predict(test[[c for c in df_feat.columns if 'S_L' in c]])
        st.session_state.p_causal = m_causal.predict(test.drop('Y', axis=1))
        st.session_state.test_idx = test.index
        st.session_state.y_hist = df_real[target]

    # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
    if 'p_causal' in st.session_state and st.session_state.last_target == target:
        idx = list(id2tech.values()).index(target)


        def simple_inv(v):
            m = np.zeros((len(v), len(id2tech)))
            m[:, idx] = v
            return scaler.inverse_transform(m)[:, idx]


        y_b = simple_inv(st.session_state.p_base)
        y_c = simple_inv(st.session_state.p_causal)

        fig = go.Figure()
        fig.add_trace(go.Scatter(x=st.session_state.y_hist.index, y=st.session_state.y_hist.values, name='çœŸå®çƒ­åº¦',
                                 line=dict(color='black')))
        fig.add_trace(
            go.Scatter(x=st.session_state.test_idx, y=y_b, name='Baseé¢„æµ‹', line=dict(color='red', dash='dash')))
        fig.add_trace(go.Scatter(x=st.session_state.test_idx, y=y_c, name='CaD-HSLé¢„æµ‹', line=dict(color='green')))
        st.plotly_chart(fig, use_container_width=True)

        if drivers:
            st.success(f"ğŸ“Œ æ ¸å¿ƒé©±åŠ¨å› å­: {', '.join(drivers)}")

        st.divider()
        st.subheader("ğŸ¤– AI æ·±åº¦å½’å› åˆ†æ")

        # LLM æŒ‰é’®
        if st.button("ç”Ÿæˆ AI ç ”æŠ¥", type="primary", use_container_width=True):
            growth = ((y_c[-1] - y_c[0]) / (y_c[0] + 1e-6)) * 100
            with st.spinner(f"æ­£åœ¨è°ƒç”¨ {LLM_MODEL_NAME} è¿›è¡Œæ¨ç†..."):
                st.session_state.report_content = generate_ai_report(target, drivers, growth)

        # æ˜¾ç¤ºæŠ¥å‘Š
        if st.session_state.report_content:
            if "âŒ" in st.session_state.report_content:
                st.error(st.session_state.report_content)
            else:
                st.markdown(f"""
                <div style="background-color:#f0f2f6; padding:20px; border-radius:10px; border-left: 5px solid #4B8BBE;">
                    <h4 style="color:#4B8BBE; margin-top:0;">ğŸ“‹ äº§ä¸šåˆ†æå¸ˆæŠ¥å‘Š</h4>
                    <p style="font-size:16px; line-height:1.6;">{st.session_state.report_content}</p>
                    <hr>
                    <p style="font-size:12px; color:grey;">* Powered by DeepSeek R1 & CaD-HSL</p>
                </div>
                """, unsafe_allow_html=True)

# --- 4. æŒ‡æ ‡è¡¨ ---
elif page == "æ¨¡å‹æ€»æŒ‡æ ‡":
    st.title("ğŸ† æ¨¡å‹æ€»æŒ‡æ ‡")
    st.dataframe(metrics_df.sort_values('Imp_MAE', ascending=False).head(20), use_container_width=True)