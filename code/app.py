import streamlit as st
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import networkx as nx
from pyvis.network import Network
import plotly.graph_objects as go
import xgboost as xgb
from sklearn.preprocessing import MinMaxScaler
import pickle
import os
import tempfile
import warnings
import sys

# ================= 1. åŸºç¡€é…ç½® =================
warnings.filterwarnings("ignore")

# è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
BASE_DIR = os.path.dirname(os.path.abspath(__file__))


def get_path(filename):
    return os.path.join(BASE_DIR, filename)


# ================= é¡µé¢é…ç½® =================
st.set_page_config(
    page_title="CaD-HSL æŠ€æœ¯è¶‹åŠ¿å¹³å°",
    page_icon="ğŸ”®",
    layout="wide"
)


# ================= æ¨¡å‹ç»“æ„ (ä¿æŒä¸€è‡´) =================
class HypergraphConv(nn.Module):
    def __init__(self, in_dim, out_dim):
        super().__init__()
        self.linear = nn.Linear(in_dim, out_dim)
        self.norm = nn.LayerNorm(out_dim)

    def forward(self, x, H, edge_weights):
        x = self.linear(x)
        edge_deg = H.sum(dim=1, keepdim=True).clamp(min=1.0)
        edge_feat = torch.matmul(H.transpose(1, 2), x) / edge_deg.transpose(1, 2)
        edge_feat = edge_feat * edge_weights.unsqueeze(-1)
        node_deg = H.sum(dim=2, keepdim=True).clamp(min=1.0)
        x_new = torch.matmul(H, edge_feat) / node_deg
        return self.norm(F.elu(x_new))


class CausalStructureLearner(nn.Module):
    def __init__(self, num_nodes, prior_matrix):
        super().__init__()
        prior_logits = torch.ones_like(prior_matrix) * -5.0
        mask = prior_matrix > 1e-4
        prior_logits[mask] = 1.0
        self.register_buffer('prior_logits', prior_logits)
        self.adj_delta = nn.Parameter(torch.zeros(num_nodes, num_nodes))

    def forward(self):
        adj = torch.sigmoid(self.prior_logits + self.adj_delta)
        return adj * (adj > 0.2).float()


class CaD_HSL_Model(nn.Module):
    def __init__(self, config, prior_matrix):
        super().__init__()
        self.node_emb = nn.Embedding(config['num_nodes'], config['embed_dim'])
        self.hg_conv1 = HypergraphConv(config['embed_dim'], config['hidden_dim'])
        self.hg_conv2 = HypergraphConv(config['hidden_dim'], config['hidden_dim'])
        self.causal_learner = CausalStructureLearner(config['num_nodes'], prior_matrix)
        self.gcn_lin = nn.Linear(config['embed_dim'], config['hidden_dim'])
        encoder_layer = nn.TransformerEncoderLayer(d_model=config['hidden_dim'] * 2, nhead=4, dim_feedforward=64,
                                                   batch_first=True)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=1)
        self.head_cls = nn.Linear(config['hidden_dim'] * 2, 1)
        self.head_reg = nn.Linear(config['hidden_dim'] * 2, 1)

    def forward(self, x, H, W): return None, None, self.causal_learner()


# ================= æ•°æ®åŠ è½½ =================
@st.cache_resource
def load_all_data():
    try:
        # 1. å­—å…¸
        with open(get_path('dictionaries.pkl'), 'rb') as f:
            dicts = pickle.load(f)
        id2tech = dicts['id2tech']
        num_nodes = len(id2tech)

        # 2. åŸå§‹åºåˆ—
        seq = torch.load(get_path('hypergraph_seq.pt'), map_location='cpu', weights_only=False)
        ts_matrix = np.zeros((len(seq), num_nodes))
        for t, item in enumerate(seq):
            if item['H'].numel() > 0:
                edge_vals = item['weights'][item['H'][1]]
                df_tmp = pd.DataFrame({'n': item['H'][0].numpy(), 'w': edge_vals.numpy()})
                for n, val in df_tmp.groupby('n')['w'].sum().items():
                    if n < num_nodes: ts_matrix[t, int(n)] = val

        scaler = MinMaxScaler()
        ts_norm = scaler.fit_transform(ts_matrix)
        df_norm = pd.DataFrame(ts_norm, columns=[id2tech[i] for i in range(num_nodes)])
        df_real = pd.DataFrame(ts_matrix, columns=[id2tech[i] for i in range(num_nodes)])

        # é¢‘ç‡å…¼å®¹ä¿®å¤
        try:
            dates = pd.date_range(end='2024-12-31', periods=len(df_norm), freq='QE')
        except:
            dates = pd.date_range(end='2024-12-31', periods=len(df_norm), freq='Q')

        df_norm.index = dates
        df_real.index = dates

        # 3. æ¨¡å‹
        device = 'cpu'
        prior = torch.load(get_path('granger_prior.pt'), map_location=device, weights_only=False)
        config = {'num_nodes': num_nodes, 'embed_dim': 32, 'hidden_dim': 32}
        model = CaD_HSL_Model(config, prior).to(device)

        model_path = get_path('cad_hsl_model.pth')
        try:
            model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))
        except:
            model.load_state_dict(torch.load(model_path, map_location=device, weights_only=False))

        model.eval()
        adj_matrix = model.causal_learner().detach().cpu().numpy()

        # 4. æŒ‡æ ‡
        metrics_df = pd.read_csv(get_path('refined_tech_metrics.csv'))

        return df_norm, df_real, adj_matrix, id2tech, scaler, metrics_df

    except FileNotFoundError as e:
        st.error(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {e.filename}ã€‚è¯·ç¡®ä¿æ‰€æœ‰æ•°æ®æ–‡ä»¶éƒ½åœ¨ {BASE_DIR} ç›®å½•ä¸‹ã€‚")
        st.stop()
    except Exception as e:
        st.error(f"âŒ æ•°æ®åŠ è½½æœªçŸ¥é”™è¯¯: {str(e)}")
        st.stop()


# åŠ è½½æ•°æ®
with st.spinner("æ­£åœ¨åˆå§‹åŒ–æ•°æ®å¼•æ“..."):
    df_norm, df_real, adj_matrix, id2tech, scaler, metrics_df = load_all_data()


# ================= è¾…åŠ©å‡½æ•°ï¼šå›¾æ„å»ºä¸ç»˜åˆ¶ (å…³é”®ä¼˜åŒ–) =================
def build_networkx_graph(adj, id2tech, threshold=0.7):
    G = nx.DiGraph()
    rows, cols = np.where(adj > threshold)
    for r, c in zip(rows, cols):
        if r == c: continue
        weight = float(adj[r, c])
        src = id2tech[r]
        dst = id2tech[c]
        G.add_edge(src, dst, weight=weight, title=f"{weight:.2f}")
    return G


def plot_pyvis(G, height="600px", select_node=None, mode="full"):
    """
    mode: 'full' (å…¨æ™¯å›¾) | 'ego' (äºŒé˜¶å°å›¾)
    """
    if len(G.nodes) == 0:
        return "<div>å›¾ä¸ºç©º</div>"

    net = Network(height=height, width="100%", bgcolor="#ffffff", font_color="black", directed=True)
    net.from_nx(G)

    # è®¾ç½®èŠ‚ç‚¹æ ·å¼
    for node in net.nodes:
        if select_node and node['id'] == select_node:
            node['color'] = '#FF5733'  # é€‰ä¸­çº¢
            node['size'] = 40
            node['label'] = f"â˜… {node['id']}"
        else:
            node['color'] = '#4B8BBE'  # æ™®é€šè“
            node['size'] = 20

    # ã€å…³é”®ä¿®æ”¹ã€‘ç‰©ç†å¼•æ“é…ç½®ï¼šå¢åŠ é˜»å°¼ï¼Œå¿«é€Ÿé™æ­¢
    if mode == "full":
        # å…¨æ™¯å›¾ï¼šä½¿ç”¨ ForceAtlas2Basedï¼Œä½†å¢åŠ  damping
        net.set_options("""
        var options = {
          "nodes": { "font": { "size": 16, "strokeWidth": 2, "strokeColor": "white" } },
          "physics": {
            "forceAtlas2Based": {
              "gravitationalConstant": -50,
              "centralGravity": 0.01,
              "springLength": 100,
              "springConstant": 0.08,
              "damping": 0.4 
            },
            "minVelocity": 0.75, 
            "solver": "forceAtlas2Based",
            "stabilization": {
              "enabled": true,
              "iterations": 200, 
              "updateInterval": 25,
              "fit": true
            }
          },
          "interaction": { "hover": true, "navigationButtons": true }
        }
        """)
    else:
        # äºŒé˜¶å›¾ï¼šä½¿ç”¨ BarnesHutï¼Œè¶…é«˜é˜»å°¼ï¼Œé¿å…ä¹±åŠ¨
        net.set_options("""
        var options = {
          "nodes": { "font": { "size": 14 } },
          "physics": {
            "barnesHut": {
              "gravitationalConstant": -3000,
              "centralGravity": 0.3,
              "springLength": 95,
              "springConstant": 0.04,
              "damping": 0.5,
              "avoidOverlap": 1
            },
            "minVelocity": 0.75,
            "solver": "barnesHut",
            "stabilization": {
              "enabled": true,
              "iterations": 200,
              "fit": true
            }
          },
          "interaction": { "hover": true, "navigationButtons": true }
        }
        """)

    # ç”Ÿæˆ HTML (Windows å…¼å®¹)
    try:
        fd, path = tempfile.mkstemp(suffix=".html")
        os.close(fd)
        net.save_graph(path)
        with open(path, 'r', encoding='utf-8') as f:
            html = f.read()
        os.remove(path)
        return html
    except Exception as e:
        return f"<div>ç»˜å›¾é”™è¯¯: {e}</div>"


# ================= ä¸»ç•Œé¢ =================
st.sidebar.title("ğŸ”® CaD-HSL é©¾é©¶èˆ±")
page = st.sidebar.radio("é€‰æ‹©åŠŸèƒ½æ¨¡å—",
                        ["å…¨æ™¯æŠ€æœ¯å…³è”å›¾", "ç‰¹å®šæŠ€æœ¯äºŒé˜¶å›¾", "è¶‹åŠ¿é¢„æµ‹ä¸å¯¹æ¯”", "æ¨¡å‹æ€»æŒ‡æ ‡"])

if page == "å…¨æ™¯æŠ€æœ¯å…³è”å›¾":
    st.title("ğŸŒ å…¨æ™¯æŠ€æœ¯å› æœå…³è”å›¾")
    col1, col2 = st.columns([3, 1])
    with col2:
        year = st.slider("é€‰æ‹©å¹´ä»½", 2012, 2024, 2024)
        threshold = st.slider("é˜ˆå€¼", 0.5, 0.95, 0.75, 0.05)

    # 1. æ„å»ºå…¨å›¾
    G_full = build_networkx_graph(adj_matrix, id2tech, threshold)

    # 2. æ ¹æ®å¹´ä»½è¿‡æ»¤æ´»è·ƒèŠ‚ç‚¹
    target_date = str(year)
    mask = df_real.index.astype(str).str.contains(target_date)
    if mask.any():
        yearly_data = df_real[mask].sum()
        active_techs = set(yearly_data[yearly_data > 0].index)
        sub_nodes = [n for n in G_full.nodes if n in active_techs]
        G_view = G_full.subgraph(sub_nodes)
    else:
        G_view = nx.DiGraph()

    with col1:
        st.markdown(f"**èŠ‚ç‚¹:** {len(G_view.nodes)} | **è¿çº¿:** {len(G_view.edges)}")
        if len(G_view.nodes) > 0:
            html = plot_pyvis(G_view, height="600px", mode="full")
            st.components.v1.html(html, height=610)
        else:
            st.warning(f"{year} å¹´æ— æ»¡è¶³æ¡ä»¶çš„æ•°æ®ã€‚")

elif page == "ç‰¹å®šæŠ€æœ¯äºŒé˜¶å›¾":
    st.title("ğŸ•¸ï¸ ç‰¹å®šæŠ€æœ¯äºŒé˜¶å…³è”å›¾")
    st.markdown("ä»…å±•ç¤ºé€‰ä¸­æŠ€æœ¯åŠå…¶ **ä¸Šæ¸¸ï¼ˆé©±åŠ¨æ–¹ï¼‰** å’Œ **ä¸‹æ¸¸ï¼ˆè¢«é©±åŠ¨æ–¹ï¼‰**ã€‚")

    col1, col2 = st.columns([1, 3])
    with col1:
        tech = st.selectbox("æ ¸å¿ƒæŠ€æœ¯", list(id2tech.values()))
        radius = st.slider("å…³è”å±‚çº§ (Hop)", 1, 2, 1)
        thresh = st.slider("è¿æ¥å¼ºåº¦é˜ˆå€¼", 0.5, 0.95, 0.7)

    with col2:
        G_full = build_networkx_graph(adj_matrix, id2tech, thresh)

        if tech in G_full.nodes:
            # æå– Ego Graph
            G_ego = nx.ego_graph(G_full, tech, radius=radius)
            # çº¯å‡€å­å›¾
            G_viz = nx.DiGraph()
            G_viz.add_nodes_from(G_ego.nodes(data=True))
            G_viz.add_edges_from(G_ego.edges(data=True))

            st.markdown(f"**{tech}** çš„ {radius} é˜¶é‚»å±…ç½‘ç»œ")
            html = plot_pyvis(G_viz, height="600px", select_node=tech, mode="ego")
            st.components.v1.html(html, height=610)
        else:
            st.info(f"æŠ€æœ¯ **{tech}** åœ¨å½“å‰é˜ˆå€¼ ({thresh}) ä¸‹æ²¡æœ‰å¼ºå…³è”èŠ‚ç‚¹ã€‚")

elif page == "è¶‹åŠ¿é¢„æµ‹ä¸å¯¹æ¯”":
    st.title("ğŸ“ˆ è¶‹åŠ¿é¢„æµ‹ä¸å½’å› ")
    target = st.selectbox("æŠ€æœ¯é€‰æ‹©", list(id2tech.values()))

    row = metrics_df[metrics_df['Tech'] == target]
    drivers = str(row['Drivers'].values[0]).split(',') if len(row) > 0 and pd.notna(row['Drivers'].values[0]) else []

    if st.button("å¼€å§‹é¢„æµ‹ (2024-2025)"):
        # æ„é€ æ•°æ®
        df_feat = pd.DataFrame(index=df_norm.index)
        df_feat['Y'] = df_norm[target]
        for l in [1, 2, 3]: df_feat[f'S_L{l}'] = df_norm[target].shift(l)
        for d in drivers:
            if d in df_norm.columns:
                df_feat[f'D_{d}_L1'] = df_norm[d].shift(1)
                df_feat[f'D_{d}_D1'] = df_norm[d].diff().shift(1)
        df_feat.dropna(inplace=True)

        train, test = df_feat.iloc[:-4], df_feat.iloc[-4:]

        # è®­ç»ƒ
        cols_base = [c for c in df_feat.columns if 'S_L' in c]
        m_base = xgb.XGBRegressor(n_estimators=100, max_depth=3).fit(train[cols_base], train['Y'])
        p_base = m_base.predict(test[cols_base])

        m_causal = xgb.XGBRegressor(n_estimators=100, max_depth=3).fit(train.drop('Y', axis=1), train['Y'])
        p_causal = m_causal.predict(test.drop('Y', axis=1))


        # è¿˜åŸ
        def inv(v):
            m = np.zeros((len(v), len(id2tech)))
            idx = list(id2tech.values()).index(target)
            m[:, idx] = v
            return scaler.inverse_transform(m)[:, idx]


        y_true = df_real[target].iloc[-4:].values
        y_b = inv(p_base)
        y_c = inv(p_causal)

        # ç»˜å›¾
        fig = go.Figure()
        y_hist = df_real[target]
        fig.add_trace(go.Scatter(x=y_hist.index, y=y_hist.values, name='çœŸå®çƒ­åº¦', line=dict(color='black')))
        fig.add_trace(go.Scatter(x=test.index, y=y_b, name='Baseé¢„æµ‹', line=dict(color='red', dash='dash')))
        fig.add_trace(go.Scatter(x=test.index, y=y_c, name='CaD-HSLé¢„æµ‹', line=dict(color='green')))
        st.plotly_chart(fig, use_container_width=True)

        mae_b = np.mean(np.abs(y_true - y_b))
        mae_c = np.mean(np.abs(y_true - y_c))
        c1, c2, c3 = st.columns(3)
        c1.metric("Base MAE", f"{mae_b:.0f}")
        c2.metric("Ours MAE", f"{mae_c:.0f}")
        c3.metric("æå‡", f"{mae_b - mae_c:.0f}", delta_color="normal")

        if drivers:
            st.success(f"æ ¸å¿ƒé©±åŠ¨å› å­: {', '.join(drivers)}")
        else:
            st.info("æ— æ˜¾è‘—å¤–éƒ¨é©±åŠ¨å› å­ã€‚")

elif page == "æ¨¡å‹æ€»æŒ‡æ ‡":
    st.title("ğŸ† æ¨¡å‹æ€»æŒ‡æ ‡")
    st.dataframe(metrics_df.sort_values('Imp_MAE', ascending=False).head(20), use_container_width=True)